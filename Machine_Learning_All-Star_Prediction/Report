This report accompanied the data, explaining my process and justifying decisions in finding an optimal model.

## Introduction

Every year, the NBA assembles two teams, one from each conference, of the best basketball players of that season; 
The All-Stars. What is the criteria to be an NBA All-Star? That's up to you! The teams are formed by a voting 
process that weighs fan votes at 50%, then addition considers player (25%) and media (25%) votes as well. There 
is no official guideline released on what comprises All-Stars. However, common opinions do arise. Points are the
most popular statistic to consider, as someone who 'gets buckets' contributes to winning and looks good doing it.
From there, things can get murkier. Some think All-Stars should have to play in most, if not all of their games. 
Some praise defensive stars, while others won't vote for them because they find defense boring. On top of all of 
that, only about 24 people are an All-Star each year. That means a player that would qualify one year might not 
another. With all of that in mind, can we predict if a player will make an All-Star team? Can we build a recipe 
that tells you how many points to score and shots to block to guarantee a spot? Time to find out.

## Data Cited

The dataframe I used was Eduardo Tocco's 'NBA Player Stats' off data world. It records the averages stats of a 
player each year in seasons from 1996-2022. The data was scraped from basketball reference. Basketball Reference 
is a well respected source and updates using official NBA data.

There isn't an All Star column in the data frame. So I manually entered that, adding an 'AS' column, and gave 1s
to the All-Stars, 0 for everyone else. I removed the rows FGA, 3PA, 2PA, FTA, and TRB due to redundancy. The A 
ending refers to 'Attempts' and this value is considered in say, FG (field goals made) and FG% (percent of field 
goals made), without these rows. TRB (True rebounds) is simply adding ORB and DRB. Pos was also disincluded to 
reduce dummy variables. In 1998-1999, the NBA had a lockout, and did not do an All Star game. Therefore, I 
removed every data point from that year. Some of the points, like FT%, are missing.

These percentages usually don't vary wildly, where someone's efficiency is superb enough to stand out. Removing data
is dangerous, as there is already a low level of All-Stars, and I felt comfortable replacing these missing data 
points with the column's average. I also clumped the Tm (Team) column into three categories: small, big, and multi. 
Big markets, like the LA Lakers, have more fans voting, and more media attention. It's often argued they have an 
easier time reaching All-Stars compared to 'Small Market Teams', like the Sacramento Kings. This split will help 
determine if that difference does comprise an advantage. Multi refers to a player that played on multiple team in 
a season.

Lets first build a correlation plot that shows the relationship between all of the variables. The focus is on 
variables' relationship with AS. PTS, FT, and FG have the largest positive correlation with AS. This aligns with 
my original theory that points will be a good indicator. Free throws make sense as well: Along with better scorers 
being fouled more, it is argued star players get favorable foul calls compared to your average Joe. After you get 
a few All-Star selections get under your belt, Free Throws might increase without anything else changing. Field 
Goals is a similar statistic to points. A slight surprise is that turnovers, a negative statistic, positively 
correlates with being an All Star. This is likely because All-Stars are asked to pass more, and will end up missing
more passes. Also, a bench player will be taken out if he throws two turnovers, where a star player will get yelled 
at and keep playing. Lets look further at All-Stars' relationships with Points, Minutes Played, and Turnovers.


The significant differences between these groups is good news. All-Stars shoot a few times more free throws compared 
to non all stars, score more points, and play more minutes. Of course, there will be players averaging 5 minutes a 
game and 1 point per game our models will easily identify as not being an All-Star. The more difficult decisions will 
be players who are close to being all stars but not quite. I ran these graphs again, but only used players who average 
at least 20 minutes a game. These are significant players in the NBA.

Minutes obviously increases significantly, as we had a minimum requirement. The results are still positive, however. 
There is still a tangible difference between All-Stars and Non-All-Stars in these categories. With this in mind, we 
can start fitting models.

## Model Fitting

First, we are going to split 75% of our data into a training set, and 25% will be put away to test our final model.
I also stratified AS, which makes sure there is a proportionally even amount of All-Star data points in both sets. 
We are going to further divide the training set into ten 'folds'. Each of these folds can behave as a testing group,
as the others are used to train for it. Then, the results are averaged off of trying that with each fold. This allows
us to do the train/test system we would do once ten times, and lowers variation in the success of testing our results.

The recipe establishes a, well, recipe for the models to follow on how to learn the data we have. All variables that 
were not used are included and available for the models. Market is dummy-variabled, so it can be represented by numbers 
instead of words. All variables are normalized by centering and scaling them. Lastly, All-Stars only make up 5% of the
dataset. Upsample allowed us to replicate and increase the amount of All-Star data points we have. I increased the 
ratio to 30%, as replicating too many points will give the model an over-reliance on those points, and could lead to 
'over-fitting', when the model is less generalized and instead better at aligning itself with its training data. 
Instead of about 400 All-Stars, we have 3000.

#### The Models

Four models will be fit. KNN, takes n (pick a number) data points close to the original, and guess what the original is 
based on those. I will make a grid with 8 different values n could take, and try all of them. Logistic Regression uses 
log-liklihood odds to place weighted coefficients in front of the predictors, to guess the liklihood of the event. 
Elastic-net log regression does standard log regression, but tries out lasso, ridge, or a combination of the two methods 
of variable analysis when making estimates. We tune by 'penalty' and 'mixture', trying a grid of different values, to 
find the best combination. Lastly, Quadratic Discriminant Analysis creates non-linear separations in the data as a way 
to categorize data points. It makes these separations by finding discriminants that maximize the variance between two 
groups while minimizing variance within those groups. This model assumes a Normal data distribution, which applies, as 
I normalized the data.

#### Fit

I create the model, and set a workflow that has the recipe above to follow. I also built the grids testing n = (1-8) 
for knn, and penalty and mixtures (0,1). I use roc_auc as a comparison metric, which uses true positive and false 
positive rates to rate performance for classification models.

KNN accuracy progressively increases with more neighbors, with n= 8 being the best model. The elastic net's best model 
is harder to cipher visually. A penalty value of .00000000001 and mixture value of .25 maximizes roc_auc. QDA and 
logistic regression only have one model, so there mean value over the 10 folds is considered. I compare below.

Elastic Net narrowly beats Logistic Regression, and knn does the worst. Both Elastic Net and Logistic Regression are valid 
choices, But I am going to continue with Elastic net, Penalty = .00000000001  and Mixture = .25 as my final model.

## Results

I now train my chosen model onto the entire training set, instead of the ten folds for cross validation. Then, I can use my 
testing set, which has been separated since the beginning, to see how this model does. Making a roc_auc curve, That sharp 
right turn at the top of the roc_auc curve is exactly how a model wants to look. For a more intuitive show of success, lets 
look at a confidence matrix.

Of the 3288 players the model predicted weren't All-Stars, it was correct about 99% of them. They labeled 96% of non All-Stars 
correctly. The model over-picked people being All-Stars, which makes sense, as there is an artificial limit on how many 
All-Stars can exist that the model doesn't consider. Of the 231 players the model deemed All-Stars, 48% actually were. The 
model was just barely right less often than wrong on guessing All-Stars. 86% of Actual All-Stars were correctly labelled, so 
the model recognized them well.

## Conclusion

Overall, machine learning models can pretty successfully determine if players are All-Stars. A lot of that success comes from 
lower level players that can clearly be outcast. However, there seems to be a consistent methodology for selections, and using 
existing statistics, We can calculate what it takes to be an NBA All Star.









